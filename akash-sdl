---
version: "2.0"
services:
  inference:
    image: ernestbs/inference-server:v0.3.2-cu12.4-ubu22
    expose:
      - port: 8000
        as: 80
        proto: tcp
        to:
          - global: true
        accept:
          - inf1.jedai.brainstems.ai
    env:
      - MODEL_REPO=TheBloke/dolphin-2.0-mistral-7B-GGUF
      - MODEL_FILE=dolphin-2.0-mistral-7b.Q4_K_M.gguf
      - REPO_URL=https://github.com/brainstems/inference-server.git
      - REPO_BRANCH=v0.3.4
profiles:
  compute:
    inference:
      resources:
        cpu:
          units: 24
        memory:
          size: 64Gi
        storage:
          - size: 100Gi
        gpu:
          units: 1
          attributes:
            vendor:
              nvidia:
                - model: a100
  placement:
    akash:
      pricing:
        inference:
          denom: uakt
          amount: 100000
deployment:
  inference:
    akash:
      profile: inference
      count: 1
